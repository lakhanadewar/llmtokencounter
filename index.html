<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>LLM Token Calculator</title>
    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            padding: 20px;
        }

        .container {
            max-width: 800px;
            margin: 0 auto;
            background: rgba(255, 255, 255, 0.95);
            backdrop-filter: blur(10px);
            border-radius: 20px;
            box-shadow: 0 20px 40px rgba(0, 0, 0, 0.1);
            overflow: hidden;
            transition: transform 0.3s ease;
        }

        .container:hover {
            transform: translateY(-5px);
        }

        .header {
            background: linear-gradient(45deg, #4facfe 0%, #00f2fe 100%);
            color: white;
            padding: 30px;
            text-align: center;
        }

        .header h1 {
            font-size: 2.5em;
            margin-bottom: 10px;
            font-weight: 300;
        }

        .header p {
            opacity: 0.9;
            font-size: 1.1em;
        }

        .content {
            padding: 40px;
        }

        .form-group {
            margin-bottom: 25px;
        }

        label {
            display: block;
            margin-bottom: 8px;
            font-weight: 600;
            color: #333;
            font-size: 1.1em;
        }

        textarea {
            width: 100%;
            min-height: 200px;
            padding: 20px;
            border: 2px solid #e1e8ed;
            border-radius: 15px;
            font-size: 1em;
            font-family: 'Courier New', monospace;
            resize: vertical;
            transition: all 0.3s ease;
            background: #fafbfc;
        }

        textarea:focus {
            outline: none;
            border-color: #4facfe;
            box-shadow: 0 0 0 3px rgba(79, 172, 254, 0.1);
            background: white;
        }

        .results {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(200px, 1fr));
            gap: 20px;
            margin-top: 30px;
        }

        .result-card {
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            color: white;
            padding: 25px;
            border-radius: 15px;
            text-align: center;
            transform: translateY(10px);
            opacity: 0;
            animation: slideUp 0.6s ease forwards;
            box-shadow: 0 10px 30px rgba(0, 0, 0, 0.2);
        }

        @keyframes slideUp {
            to {
                transform: translateY(0);
                opacity: 1;
            }
        }

        .result-card:nth-child(2) {
            animation-delay: 0.1s;
        }

        .result-card:nth-child(3) {
            animation-delay: 0.2s;
        }

        .result-card:nth-child(4) {
            animation-delay: 0.3s;
        }

        .result-value {
            font-size: 2.5em;
            font-weight: bold;
            margin-bottom: 10px;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.3);
        }

        .result-label {
            font-size: 0.9em;
            opacity: 0.9;
            text-transform: uppercase;
            letter-spacing: 1px;
        }

        .all-models-tokens {
            background: linear-gradient(135deg, #ff9a9e 0%, #fecfef 100%);
            border-radius: 15px;
            padding: 25px;
            margin: 25px 0;
            color: white;
        }

        .all-models-tokens h3 {
            margin-bottom: 20px;
            font-size: 1.3em;
            text-align: center;
            text-shadow: 0 2px 4px rgba(0, 0, 0, 0.2);
        }

        .model-tokens-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(280px, 1fr));
            gap: 15px;
        }

        .model-token-card {
            background: rgba(255, 255, 255, 0.15);
            backdrop-filter: blur(10px);
            border: 1px solid rgba(255, 255, 255, 0.2);
            border-radius: 12px;
            padding: 18px;
            transition: all 0.3s ease;
        }

        .model-token-card:hover {
            background: rgba(255, 255, 255, 0.25);
            transform: translateY(-3px);
            box-shadow: 0 8px 25px rgba(0, 0, 0, 0.15);
        }

        .model-name {
            font-weight: 600;
            font-size: 1.1em;
            margin-bottom: 10px;
            text-shadow: 0 1px 2px rgba(0, 0, 0, 0.2);
        }

        .token-display {
            display: flex;
            justify-content: space-between;
            align-items: center;
            margin-bottom: 8px;
        }

        .token-number {
            font-size: 1.4em;
            font-weight: bold;
            color: #fff;
        }

        .cost-display {
            font-size: 0.9em;
            opacity: 0.9;
        }

        .calculation-note {
            background: #f8f9ff;
            border: 2px solid #e1e8ed;
            border-radius: 15px;
            padding: 25px;
            margin: 25px 0;
        }

        .calculation-note h3 {
            color: #4facfe;
            margin-bottom: 15px;
            font-size: 1.3em;
        }

        .calculation-note h4 {
            color: #333;
            margin: 15px 0 8px 0;
            font-size: 1.1em;
        }

        .calculation-details {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(300px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }

        .calc-method {
            background: white;
            padding: 18px;
            border-radius: 10px;
            border: 1px solid #e1e8ed;
        }

        .model-specifics {
            background: white;
            padding: 20px;
            border-radius: 10px;
            border: 1px solid #e1e8ed;
            margin: 15px 0;
        }

        .model-specifics ul {
            margin: 10px 0;
            padding-left: 20px;
        }

        .model-specifics li {
            margin: 8px 0;
            line-height: 1.5;
        }

        .note-disclaimer {
            background: linear-gradient(135deg, #ffecd2 0%, #fcb69f 100%);
            color: #8b4513;
            padding: 15px;
            border-radius: 10px;
            margin-top: 20px;
            font-style: italic;
        }

        @media (max-width: 600px) {
            .header h1 {
                font-size: 2em;
            }
            
            .content {
                padding: 20px;
            }
            
            .results {
                grid-template-columns: 1fr;
            }
        }
    </style>
</head>
<body>
    <div class="container">
        <div class="header">
            <h1>ü§ñ LLM Token Calculator</h1>
            <p>Calculate tokens and estimate costs for popular language models</p>
        </div>

        <div class="content">
            <div class="form-group">
                <label for="text-input">Enter your text:</label>
                <textarea id="text-input" placeholder="Type or paste your text here to calculate tokens..."></textarea>
            </div>

            <div class="results" id="results">
                <div class="result-card">
                    <div class="result-value" id="token-count">0</div>
                    <div class="result-label">Average Tokens</div>
                </div>
                <div class="result-card">
                    <div class="result-value" id="character-count">0</div>
                    <div class="result-label">Characters</div>
                </div>
                <div class="result-card">
                    <div class="result-value" id="word-count">0</div>
                    <div class="result-label">Words</div>
                </div>
                <div class="result-card">
                    <div class="result-value" id="ratio">0</div>
                    <div class="result-label">Chars/Token</div>
                </div>
            </div>

            <div class="all-models-tokens" id="all-models-tokens">
                <h3>üìä Token Count Across All Models</h3>
                <div class="model-tokens-grid" id="model-tokens-grid">
                    <!-- Dynamic content will be inserted here -->
                </div>
            </div>

            <div class="calculation-note" id="calculation-note">
                <h3>üìã How We Calculate Tokens</h3>
                <p><strong>Token Estimation Method:</strong> We use model-specific character-to-token ratios combined with word-based analysis to provide accurate estimates. Each model has different tokenization algorithms:</p>
                
                <div class="calculation-details">
                    <div class="calc-method">
                        <h4>üî§ Character-Based Method (70% weight)</h4>
                        <p>Text length √∑ Average characters per token for each model</p>
                    </div>
                    <div class="calc-method">
                        <h4>üìù Word-Based Method (30% weight)</h4>
                        <p>Word count √ó 1.3 (average word-to-token ratio)</p>
                    </div>
                </div>
                
                <div class="model-specifics">
                    <h4>üìä Model-Specific Tokenization Ratios:</h4>
                    <ul>
                        <li><strong>GPT Models:</strong> ~4.0 characters per token (tiktoken cl100k_base)</li>
                        <li><strong>Claude Models:</strong> ~3.8 characters per token (optimized tokenization)</li>
                        <li><strong>Gemini Pro:</strong> ~4.2 characters per token</li>
                        <li><strong>Llama 2 70B:</strong> ~4.5 characters per token</li>
                        <li><strong>Mistral 7B:</strong> ~4.3 characters per token</li>
                    </ul>
                </div>
                
                <p class="note-disclaimer">
                    <strong>Note:</strong> These are estimates based on average tokenization patterns. Actual token counts may vary slightly depending on text content, special characters, and model-specific tokenizer implementations. For precise billing, always refer to the official API token counts.
                </p>
            </div>
        </div>
    </div>

    <script>
        // Wait for DOM to be fully loaded
        document.addEventListener('DOMContentLoaded', function() {
            const modelData = {
                'gpt-4': {
                    name: 'GPT-4',
                    description: 'OpenAI\'s most capable model with advanced reasoning and multimodal capabilities.',
                    avgCharsPerToken: 4,
                    inputCostPer1M: 30.00,
                    outputCostPer1M: 60.00
                },
                'gpt-3.5-turbo': {
                    name: 'GPT-3.5 Turbo',
                    description: 'Fast and efficient model optimized for chat applications.',
                    avgCharsPerToken: 4,
                    inputCostPer1M: 0.50,
                    outputCostPer1M: 1.50
                },
                'claude-3-opus': {
                    name: 'Claude 3 Opus',
                    description: 'Anthropic\'s most powerful model with exceptional performance.',
                    avgCharsPerToken: 3.8,
                    inputCostPer1M: 15.00,
                    outputCostPer1M: 75.00
                },
                'claude-3-sonnet': {
                    name: 'Claude 3 Sonnet',
                    description: 'Balanced model offering strong performance with good speed.',
                    avgCharsPerToken: 3.8,
                    inputCostPer1M: 3.00,
                    outputCostPer1M: 15.00
                },
                'claude-3-haiku': {
                    name: 'Claude 3 Haiku',
                    description: 'Fastest and most compact model for near-instant responsiveness.',
                    avgCharsPerToken: 3.8,
                    inputCostPer1M: 0.25,
                    outputCostPer1M: 1.25
                },
                'gemini-pro': {
                    name: 'Gemini Pro',
                    description: 'Google\'s flagship model with multimodal capabilities.',
                    avgCharsPerToken: 4.2,
                    inputCostPer1M: 0.50,
                    outputCostPer1M: 1.50
                },
                'llama-2-70b': {
                    name: 'Llama 2 70B',
                    description: 'Meta\'s open-source large language model.',
                    avgCharsPerToken: 4.5,
                    inputCostPer1M: 0.90,
                    outputCostPer1M: 0.90
                },
                'mistral-7b': {
                    name: 'Mistral 7B',
                    description: 'Efficient open-source model with strong performance.',
                    avgCharsPerToken: 4.3,
                    inputCostPer1M: 0.25,
                    outputCostPer1M: 0.25
                }
            };

            // Get DOM elements
            const textInput = document.getElementById('text-input');
            const tokenCount = document.getElementById('token-count');
            const characterCount = document.getElementById('character-count');
            const wordCount = document.getElementById('word-count');
            const ratio = document.getElementById('ratio');
            const modelTokensGrid = document.getElementById('model-tokens-grid');

            function estimateTokens(text, avgCharsPerToken) {
                if (!text.trim()) return 0;
                
                const words = text.trim().split(/\s+/).length;
                const chars = text.length;
                
                // Combine multiple estimation methods for better accuracy
                const charBasedEstimate = Math.ceil(chars / avgCharsPerToken);
                const wordBasedEstimate = Math.ceil(words * 1.3);
                
                return Math.round((charBasedEstimate * 0.7) + (wordBasedEstimate * 0.3));
            }

            function updateAllModelsDisplay() {
                const text = textInput.value;
                let html = '';
                
                Object.entries(modelData).forEach(([key, model]) => {
                    const tokens = estimateTokens(text, model.avgCharsPerToken);
                    const cost = tokens > 0 ? (tokens / 1000000) * model.inputCostPer1M : 0;
                    
                    html += `
                        <div class="model-token-card">
                            <div class="model-name">${model.name}</div>
                            <div class="token-display">
                                <span>Tokens:</span>
                                <span class="token-number">${tokens.toLocaleString()}</span>
                            </div>
                            <div class="cost-display">
                                Input Cost: $${cost.toFixed(6)}
                            </div>
                        </div>
                    `;
                });
                
                modelTokensGrid.innerHTML = html;
            }

            function updateCalculations() {
                const text = textInput.value;
                
                // Calculate average across all models
                let totalTokens = 0;
                let modelCount = Object.keys(modelData).length;
                
                Object.values(modelData).forEach(model => {
                    totalTokens += estimateTokens(text, model.avgCharsPerToken);
                });
                
                const averageTokens = Math.round(totalTokens / modelCount);
                const characters = text.length;
                const words = text.trim() ? text.trim().split(/\s+/).length : 0;
                const charsPerToken = averageTokens > 0 ? (characters / averageTokens).toFixed(1) : 0;

                // Update display
                animateCounter(tokenCount, averageTokens);
                animateCounter(characterCount, characters);
                animateCounter(wordCount, words);
                ratio.textContent = charsPerToken;
                
                // Update all models display
                updateAllModelsDisplay();
            }

            function animateCounter(element, targetValue) {
                const currentValue = parseInt(element.textContent) || 0;
                const increment = Math.ceil(Math.abs(targetValue - currentValue) / 20);
                
                const animate = () => {
                    const current = parseInt(element.textContent) || 0;
                    if (current !== targetValue) {
                        if (current < targetValue) {
                            element.textContent = Math.min(current + increment, targetValue);
                        } else {
                            element.textContent = Math.max(current - increment, targetValue);
                        }
                        requestAnimationFrame(animate);
                    }
                };
                
                animate();
            }

            // Event listeners
            textInput.addEventListener('input', updateCalculations);

            // Initialize
            updateCalculations();

            // Add sample text after a short delay
            setTimeout(() => {
                textInput.value = "Hello! This is a sample text to demonstrate the LLM token calculator. You can replace this with your own content to see how many tokens it would consume and estimate the associated costs for different language models.";
                updateCalculations();
            }, 500);
        });
    </script>
</body>
</html>